{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSEY4tmOU6sAOPBqr8XdIL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/endophenotype/Spark/blob/main/Spark_%D0%B7%D0%B0%D0%B3%D1%80%D1%83%D0%B7%D0%BA%D0%B0_%D0%BF%D0%B0%D0%BA%D0%B5%D1%82%D0%B0_%D1%81%D0%BE%D0%B1%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D1%85_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85_%D0%B8_%D1%8D%D0%BA%D1%81%D0%BF%D0%BB%D1%83%D0%B0%D1%82%D0%B0%D1%86%D0%B8%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHZftUpcTFYB"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\"\n",
        "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\""
      ],
      "metadata": {
        "id": "4sJTCzVQTOtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "iBW0kK3NTRe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.pandas as ps\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "rAH7Y4FeTTMr",
        "outputId": "da0c221c-048f-404d-f068-3d55cd93ae42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2db653ea40>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5e06e3af9a18:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Реализовать код загрузки пакета на собственных данных и проэксплуатировать его, сделать выводы **"
      ],
      "metadata": {
        "id": "BafvqGvefMCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Фреймворк Spark может работать с данными, которые загружаются из различных файлов, рассмотрим наиболее популярные форматы:\n",
        "\n",
        ".txt\n",
        "\n",
        ".csv\n",
        "\n",
        ".json"
      ],
      "metadata": {
        "id": "6_n03c1cixlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**.txt**"
      ],
      "metadata": {
        "id": "Vj2JxMsBpu66"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OZRJKDedPNF",
        "outputId": "fe5a0df5-f554-4829-f452-d12036ff94d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['t1,g1', 't1,g2', 't2,g3', 't2,g4', 't3,g7', 't3,g8', 't3,g9']\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "appName = 'appName'\n",
        "master = 'local[*]'\n",
        "conf = SparkConf().setAppName(appName).setMaster(master)\n",
        "sc = spark.sparkContext\n",
        "R = sc.textFile(\"/content/TG.txt\");\n",
        "print(R.collect())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**.csv**"
      ],
      "metadata": {
        "id": "N2ev6yo0psKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('TG.csv', header=True, inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKob1c3Bnv6s",
        "outputId": "ed134bae-7f4d-43a6-df4b-15261db04827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------+\n",
            "|number;name;fmane;sname |\n",
            "+------------------------+\n",
            "|                 1;T;G;Y|\n",
            "|                 2;T;G;Y|\n",
            "|                 3;G;G;Y|\n",
            "|                 4;T;G;Y|\n",
            "|                 5;G;G;Y|\n",
            "+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**.json**"
      ],
      "metadata": {
        "id": "6JHQh-z3pp8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spark is an existing SparkSession\n",
        "df = spark.read.json(\"/content/TG1.json\")\n",
        "\n",
        "# spark, df are from the previous example\n",
        "# Print the schema in a tree format\n",
        "df.printSchema()\n",
        "\n",
        "# Select only the \"name\" column\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf_r3Ir-pkVd",
        "outputId": "a6b7531e-6e16-466b-e0da-0e3be53c7c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Array: array (nullable = true)\n",
            " |    |-- element: long (containsNull = true)\n",
            " |-- Boolean: boolean (nullable = true)\n",
            " |-- FName: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Null: string (nullable = true)\n",
            " |-- Number: long (nullable = true)\n",
            " |-- Object: struct (nullable = true)\n",
            " |    |-- a: string (nullable = true)\n",
            " |    |-- c: string (nullable = true)\n",
            "\n",
            "+---------+-------+-------+----+----+------+------+\n",
            "|    Array|Boolean|  FName|Name|Null|Number|Object|\n",
            "+---------+-------+-------+----+----+------+------+\n",
            "|[1, 2, 3]|   true|Golubev| Tim|null|   123|{b, d}|\n",
            "+---------+-------+-------+----+----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "При помощи Spark можно работать с различными типами данных, выбор зависит от потребностей разработчика"
      ],
      "metadata": {
        "id": "984etyIpqBuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Реализовать код выбора и доступа к данным (DataFrame.select()) на собственных данных и проэксплуатировать его, сделать выводы **"
      ],
      "metadata": {
        "id": "RSmjXGl8oEpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spark is an existing SparkSession\n",
        "df = spark.read.json(\"/content/TG1.json\")\n",
        "\n",
        "# spark, df are from the previous example\n",
        "# Print the schema in a tree format\n",
        "df.printSchema()\n",
        "\n",
        "# Select only the \"name\" column\n",
        "df.select(\"Name\").show()\n",
        "df.select(\"FName\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ7t-NmqoRi-",
        "outputId": "b9eae71a-f414-47f8-84b1-3b1bdfd5eea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Array: array (nullable = true)\n",
            " |    |-- element: long (containsNull = true)\n",
            " |-- Boolean: boolean (nullable = true)\n",
            " |-- FName: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Null: string (nullable = true)\n",
            " |-- Number: long (nullable = true)\n",
            " |-- Object: struct (nullable = true)\n",
            " |    |-- a: string (nullable = true)\n",
            " |    |-- c: string (nullable = true)\n",
            "\n",
            "+----+\n",
            "|Name|\n",
            "+----+\n",
            "| Tim|\n",
            "+----+\n",
            "\n",
            "+-------+\n",
            "|  FName|\n",
            "+-------+\n",
            "|Golubev|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью кода выбора и доступа к данным (DataFrame.select()) можно выбрать и работать с фрагментом данных"
      ],
      "metadata": {
        "id": "YuVX4BlzqKrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Реализовать код Spark ввод-вывод на собственных данных и проэксплуатировать его, сделать выводы **"
      ],
      "metadata": {
        "id": "JyOSengaqnWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.read.csv('TG.csv',inferSchema=True, header=True)\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7B2_V0Pqbf7",
        "outputId": "ca7db5dd-96aa-47d7-a43b-8ad89794f32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------+\n",
            "|number;name;fmane;sname |\n",
            "+------------------------+\n",
            "|                 1;T;G;Y|\n",
            "|                 2;T;G;Y|\n",
            "|                 3;G;G;Y|\n",
            "|                 4;T;G;Y|\n",
            "|                 5;G;G;Y|\n",
            "+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запишем данные в новый файл"
      ],
      "metadata": {
        "id": "cVvRurQ2tHbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.write.csv(\"TimG.csv\")"
      ],
      "metadata": {
        "id": "tRPZsILTsrOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим"
      ],
      "metadata": {
        "id": "X7T463ggtFbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfcheck = spark.read.csv('TimG.csv',inferSchema=True, header=True)\n",
        "dfcheck.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S35vUVYOs-wk",
        "outputId": "887b2e1c-5038-444b-df8f-780a04831fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|1;T;G;Y|\n",
            "+-------+\n",
            "|2;T;G;Y|\n",
            "|3;G;G;Y|\n",
            "|4;T;G;Y|\n",
            "|5;G;G;Y|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод: При помощи данного метода можно вводить данные в spark, проводить над ними манипуляции, а после выгрузить при помощи записи и дальнейшего вывода файла"
      ],
      "metadata": {
        "id": "KINOrJygtOcM"
      }
    }
  ]
}